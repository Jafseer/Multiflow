{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The prequential evaluation delayed- Time stamp data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prequential evaluation delayed is designed specifically for stream settings, in the sense that each sample serves two purposes, and that samples are analysed sequentially, in order of arrival, and are used to update the model only when their label are available, given their timestamps (arrival and available times)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method consists of using each sample to test the model, which means to make a predictions, and then the same sample is used to train the model (partial fit) after its label is available after a certain delay. This way the model is always tested on samples that it hasnâ€™t seen yet and updated on samples that have their labels available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class **skmultiflow.evaluation.EvaluatePrequentialDelayed(n_wait=200, max_samples=100000, batch_size=1, pretrain_size=200, max_time=inf, metrics=None, output_file=None, show_plot=False, restart_stream=True, data_points_for_classification=False)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first example demonstrates how to evaluate one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skmultiflow.data import TemporalDataStream\n",
    "from skmultiflow.trees import HoeffdingTreeClassifier\n",
    "from skmultiflow.evaluation import EvaluatePrequentialDelayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns used to get the data, label and time from iris_timestamp dataset\n",
    "DATA_COLUMNS = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
    "LABEL_COLUMN = \"label\"\n",
    "TIME_COLUMN = \"timestamp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a csv with stream data\n",
    "data = pd.read_csv(\"D:/Streaming data set/streaming-datasets-master/iris_timestamp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time column to datetime\n",
    "data[TIME_COLUMN] = pd.to_datetime(data[TIME_COLUMN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by time\n",
    "data = data.sort_values(by=TIME_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X, y and time\n",
    "X = data[DATA_COLUMNS].values\n",
    "y = data[LABEL_COLUMN].values\n",
    "time = data[TIME_COLUMN].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a delay of 1 day\n",
    "delay_time = np.timedelta64(1, \"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the stream\n",
    "stream = TemporalDataStream(X, y, time, sample_delay=delay_time, ordered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model\n",
    "ht = HoeffdingTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the evaluator\n",
    "evaluator = EvaluatePrequentialDelayed(batch_size=1,\n",
    "                                pretrain_size=X.shape[0]//2,\n",
    "                                max_samples=X.shape[0],\n",
    "                                output_file='results_delay.csv',\n",
    "                                metrics=['accuracy', 'recall', 'precision', 'f1', 'kappa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prequential Evaluation Delayed\n",
      "Evaluating 1 target(s).\n",
      "Pre-training on 150 sample(s).\n",
      "Evaluating...\n",
      " ###################- [95%] [1.21s]Processed samples: 300\n",
      "Mean performance:\n",
      "HT - Accuracy     : 0.5882\n",
      "HT - Kappa        : 0.3824\n",
      "HT - Precision: 0.5938\n",
      "HT - Recall: 0.5882\n",
      "HT - F1 score: 0.5465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HoeffdingTreeClassifier(binary_split=False, grace_period=200,\n",
       "                         leaf_prediction='nba', max_byte_size=33554432,\n",
       "                         memory_estimate_period=1000000, nb_threshold=0,\n",
       "                         no_preprune=False, nominal_attributes=None,\n",
       "                         remove_poor_atts=False, split_confidence=1e-07,\n",
       "                         split_criterion='info_gain', stop_mem_management=False,\n",
       "                         tie_threshold=0.05)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run evaluation\n",
    "evaluator.evaluate(stream=stream, model=ht, model_names=['HT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The second example demonstrates how to compare two models-(Hoeffding Tree & Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultiflow.bayes import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prequential Evaluation Delayed\n",
      "Evaluating 1 target(s).\n",
      "Pre-training on 150 sample(s).\n",
      "Evaluating...\n",
      "Processed samples: 300\n",
      "Mean performance:\n",
      "HT - Accuracy     : 0.5926\n",
      "HT - Kappa        : 0.3889\n",
      "HT - Precision: 0.5931\n",
      "HT - Recall: 0.5926\n",
      "HT - F1 score: 0.5487\n",
      "NB - Accuracy     : 0.5926\n",
      "NB - Kappa        : 0.3889\n",
      "NB - Precision: 0.5931\n",
      "NB - Recall: 0.5926\n",
      "NB - F1 score: 0.5487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HoeffdingTreeClassifier(binary_split=False, grace_period=200,\n",
       "                         leaf_prediction='nba', max_byte_size=33554432,\n",
       "                         memory_estimate_period=1000000, nb_threshold=0,\n",
       "                         no_preprune=False, nominal_attributes=None,\n",
       "                         remove_poor_atts=False, split_confidence=1e-07,\n",
       "                         split_criterion='info_gain', stop_mem_management=False,\n",
       "                         tie_threshold=0.05),\n",
       " NaiveBayes(nominal_attributes=None)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a delay of 30 minutes\n",
    "delay_time = np.timedelta64(30, \"m\")\n",
    "# Set the stream\n",
    "stream = TemporalDataStream(X, y, time, sample_delay=delay_time, ordered=False)\n",
    "# Set the models\n",
    "ht = HoeffdingTreeClassifier()\n",
    "nb = NaiveBayes()\n",
    "\n",
    "evaluator = EvaluatePrequentialDelayed(batch_size=1,\n",
    "                                pretrain_size=X.shape[0]//2,\n",
    "                                max_samples=X.shape[0],\n",
    "                                output_file='results_delay.csv',\n",
    "                                metrics=['accuracy', 'recall', 'precision', 'f1', 'kappa'])\n",
    "\n",
    "# Run evaluation\n",
    "evaluator.evaluate(stream=stream, model=[ht, nb], model_names=['HT', 'NB'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very Fast Decision Rules classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Nominal attributes have been defined, will consider all attributes as numerical\n"
     ]
    }
   ],
   "source": [
    "from skmultiflow.rules import VeryFastDecisionRulesClassifier\n",
    "\n",
    "dr = VeryFastDecisionRulesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prequential Evaluation Delayed\n",
      "Evaluating 1 target(s).\n",
      "Pre-training on 150 sample(s).\n",
      "Evaluating...\n",
      "Processed samples: 300\n",
      "Mean performance:\n",
      "DR - Accuracy     : 0.5926\n",
      "DR - Kappa        : 0.3889\n",
      "DR - Precision: 0.5931\n",
      "DR - Recall: 0.5926\n",
      "DR - F1 score: 0.5487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[VeryFastDecisionRulesClassifier(drift_detector=None, expand_confidence=1e-07,\n",
       "                                 expand_criterion='info_gain', grace_period=200,\n",
       "                                 max_rules=1000, min_weight=100,\n",
       "                                 nb_prediction=True, nb_threshold=0,\n",
       "                                 nominal_attributes=[], ordered_rules=True,\n",
       "                                 remove_poor_atts=False,\n",
       "                                 rule_prediction='first_hit',\n",
       "                                 tie_threshold=0.05)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = EvaluatePrequentialDelayed(batch_size=1,\n",
    "                                pretrain_size=X.shape[0]//2,\n",
    "                                max_samples=X.shape[0],\n",
    "                                output_file='results_delay.csv',\n",
    "                                metrics=['accuracy', 'recall', 'precision', 'f1', 'kappa'])\n",
    "\n",
    "# Run evaluation\n",
    "evaluator.evaluate(stream=stream, model=[dr], model_names=['DR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
